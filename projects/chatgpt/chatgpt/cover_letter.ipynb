{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt: str, model: str=\"gpt-3.5-turbo\", temp: float=0): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temp, # this is the degree of randomness of the model's output\n",
    "        frequency_penalty=0.5\n",
    "    )\n",
    "    # print(response)\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import PurePath\n",
    "\n",
    "def save_response(response: str, path: str='.'):\n",
    "    global v\n",
    "    filename = f'letter_v{v:02d}.txt'\n",
    "    filepath = PurePath(path, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(response)\n",
    "    v += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"\"\"\n",
    "Senior Data Scientist\n",
    "Diligent and proficient data science professional with experience using programming, machine learning, statistics, analytics, and mathematics to uncover insights in data sets, inform product design and generate business value across diverse industries. Proven track record of performing data wrangling operations to collect, clean and transform data from different sources to develop and deploy classification, regression, and clustering models. Known for curiosity, critical thinking, creative problem-solving, rigorous testing, cross-functional teamwork, and flexibility. Driven by a desire to cooperate and win as a team while personally advocating and communicating best practices for sustainable success.\n",
    "AREAS OF EXPERTISE\n",
    "Data Warehousing | Applied Mathematics | Data Visualization | Machine Learning | Time Series Forecasting | Network Science | Data Analysis | Teamwork\n",
    "TECHNICAL SKILLS\n",
    "Programming: Python (pandas, scikit-learn, PyTorch, TensorFlow, NumPy, matplotlib, seaborn), R, SQL Software: Mathematica, MATLAB; Cloud: AWS (EC2, S3, RDS, SageMaker, CloudWatch)\n",
    "Tools: Docker, git, Github, Jira, Confluence, LaTeX\n",
    "EXPERIENCE\n",
    "Thermo Fisher Scientific, South San Francisco, CA 01/2021 - 11/2022 \n",
    "Staff Engineer, Software and Machine Learning\n",
    "- Built reusable AWS SageMaker infrastructure for machine learning training and inference pipelines in a nascent MLOps system while providing transformational thought leadership.\n",
    "- Developed optical simulations and ETL pipelines in Python for new PCR instruments allowing quick iterations of analysis of spectral data from lab scientists.\n",
    "- Designed deep learning algorithms and improved data quality for COVID-19 detection by PCR.\n",
    "- Established best practices for machine learning code, dataset tracking, and experiment training.\n",
    "- Validated algorithms for DNA sequencing deployed on capillary electrophoresis instruments using\n",
    "a variety of custom scripts and apps in MATLAB and Python on carefully selected data samples.\n",
    "Eko Devices, Berkeley, CA 10/2018 - 11/2020 \n",
    "Senior Data Scientist\n",
    "- Coded and deployed first FDA-cleared deep learning model for the interpretation of heart sounds by two on-market Eko electronic stethoscopes connected to production mobile apps\n",
    "- Coauthored peer-reviewed publication on patented heart murmur detection algorithm.\n",
    "- Designed and implemented Eko's first data warehouse in MySQL to merge disparate data\n",
    "sources into a single source of truth enabling streamlined analysis and model training.\n",
    "- Created the necessary labeled data for classification tasks through iterative improvement of\n",
    "annotation strategies using feedback from expert cardiologists leading to higher quality data.\n",
    "- Conducted model performance analyses and experiment statistics resulting in FDA approval.\n",
    "Cogito Corp., Boston, MA 12/2016 - 05/2018 \n",
    "Senior Data Analyst\n",
    "- Developed artificial intelligence models in TensorFlow for guidance during telephone conversations resulting in higher customer satisfaction scores and greater employee retention.\n",
    "- Showed Cogito improved clients' KPIs through statistics (e.g., t-tests) and visualization.\n",
    "- Analyzed complex user data from Cogito's mobile mental health app using R Shiny to create the\n",
    "dashboard while mentoring an intern.\n",
    "\n",
    "Lux Research, Inc., Boston, MA 11/2015 - 09/2016 \n",
    "Data Scientist\n",
    "- Built machine learning models to predict customer ROI using Lux's proprietary data assets and external APIs. Communicated results to executives to drive insight and marketing initiatives.\n",
    "- Advanced Lux's Grid Network Analysis model of emission factors for electricity generated and transferred across grids using linear algebra and coauthored a peer-reviewed publication. Developed a Flask app for interactive visualization and exploratory data analysis.\n",
    "- Created Django app for accurate supply chain sustainability accounting and life cycle analysis.\n",
    "Harvard University, Cambridge, MA 08/2012 - 07/2015 \n",
    "Preceptor (lecturer) in Applied Mathematics\n",
    "- Taught mathematical modeling and data science using MATLAB and Python, linear algebra, differential equations, and graduate perturbation theory.\n",
    "- Hired and managed more than 10 teaching assistants and graders.\n",
    "- Founded and advised student chapter of Society for Industrial and Applied Mathematics\n",
    "- Conducted evolutionary game theory research and simulation resulting in a publication.\n",
    "University of California, Merced, CA 08/2010 - 07/2012 Visiting Assistant Professor, Merced\n",
    "- Published highly cited research in computational fluid dynamics related to ocean pollution.\n",
    "- Taught and developed 6 mathematics courses ranging from 20 to 160 students.\n",
    "\n",
    "EDUCATION\n",
    "Doctor of Philosophy (PhD), Applied Mathematics\n",
    "Columbia University, New York, NY\n",
    "Master of Science (MS), Applied Mathematics and Applied Physics\n",
    "Columbia University, New York, NY\n",
    "Bachelor of Science (BS), Applied Mathematics, Computing\n",
    "University of California, Los Angeles, CA\n",
    "PROFESSIONAL DEVELOPMENT\n",
    "Deep Learning Specialization (5 courses, deeplearning.ai), Coursera\n",
    "Data Science in R Specialization (5 courses, Johns Hopkins University), Coursera\n",
    "SELECTED PROJECTS AND PUBLICATIONS\n",
    "Simulation of cooperation evolution on a network [publication, preprint, poster]\n",
    "Coded evolutionary game theory algorithms in python to simulate the emergence of cooperation among individuals connected by a time-varying social network.\n",
    "Orchestrated parallel computations on high-performance compute clusters.\n",
    "Computational fluid dynamics of oil droplets in a stratified ocean [publication]\n",
    "Simulated surface tension driven drop motion in C++ showing drops can levitate.\n",
    "Analyzed and visualized 20GB of data in MATLAB.\n",
    "Dissertation: “Dynamics of a Bubble in a Compressible Fluid” [publication]\n",
    "Used Mathematica for computational algebra and C++ (parallelized using PETSc) to simulate gas bubble shape dynamics using the boundary element method (BEM).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = \"XXXXX\"\n",
    "role = \"Senior Data Scientist\"\n",
    "\n",
    "jd = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "motivation = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Dear ChatGPT,\n",
    "\n",
    "I am currently applying for {role} at {company} and I could use your expertise \\\n",
    "in crafting a compelling cover letter that showcases my unique qualifications from my resume \\\n",
    "and aligns \\\n",
    "with the job requirements. The letter should be written from me to the hiring manager. The \\\n",
    "tone should be sophisticated and the diction and sentence structure should be varied and \\\n",
    "interesting but not repetitive.\n",
    "\n",
    "I will give you the job description which is delimited with triple backticks.\n",
    "```{jd}```\n",
    "\n",
    "I will also give you my resume which is delimited with angle brackets. Use only my two most recent \\\n",
    "experiences to describe my qualifications for the job to which I'm applying.\n",
    "<{resume}>\n",
    "\n",
    "In addition to experience in my resume matching text in the job description, please include \\\n",
    "my particular motivation and interest in this job, which is delimited by square brackets.\n",
    "[{motivation}]\n",
    "\n",
    "Please keep the letter at 300 words and start the letter with 'Dear Hiring Manager'.\n",
    "\n",
    "Thank you for your support.  I look forward to your creative concise cover letter.\n",
    "\n",
    "Best regards,\n",
    "Avi Shapiro\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(prompt, temp=0.5)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt-jAfVekuD-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
